{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581afcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3792c088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        latitude   longitude state disc_clean_date  Temp_pre_15  Temp_pre_7  \\\n",
      "159    39.965000 -122.318056    CA       8/22/1998    22.357143   21.400000   \n",
      "192    40.228611 -120.671389    CA       6/27/2006    13.265223   15.781065   \n",
      "308    39.951177 -122.200397    CA       5/25/2014    20.441860   19.787330   \n",
      "419    39.936181 -122.093450    CA       8/27/2004     0.000000    0.000000   \n",
      "453    40.121944 -122.583889    CA       6/18/1996    27.206389   25.695833   \n",
      "...          ...         ...   ...             ...          ...         ...   \n",
      "55066  40.343056 -123.383056    CA       7/31/2015    16.234259   16.892857   \n",
      "55067  40.609722 -123.559444    CA       7/30/2015    16.125000   16.623016   \n",
      "55070  40.680000 -123.416667    CA       7/30/2015    16.125000   16.623016   \n",
      "55196  39.911940 -122.493060    CA       7/29/2015    27.802222   27.876543   \n",
      "55199  40.963600 -120.114200    CA        8/3/2015    20.612145   21.403933   \n",
      "\n",
      "       Wind_pre_15  Wind_pre_7  Hum_pre_15  Hum_pre_7  Prec_pre_15  \\\n",
      "159       1.092857    2.040000    0.000000   0.000000          0.0   \n",
      "192       1.497429    1.110355   60.522481  58.560897          2.5   \n",
      "308       2.965333    3.323636   39.539363  52.244240          0.0   \n",
      "419       0.000000    0.000000    0.000000   0.000000          0.0   \n",
      "453       2.839167    2.954762   39.416667  42.446429          0.0   \n",
      "...            ...         ...         ...        ...          ...   \n",
      "55066     3.703889    3.885119   77.401309  75.085779          0.0   \n",
      "55067     3.769630    4.035913   78.199569  76.502193          0.0   \n",
      "55070     3.769630    4.035913   78.199569  76.502193          0.0   \n",
      "55196     2.808463    4.445679   36.538975  31.074074          0.0   \n",
      "55199     2.592593    2.075000   39.942935  33.509202          7.9   \n",
      "\n",
      "       Prec_pre_7  fire  \n",
      "159           0.0     1  \n",
      "192           0.0     1  \n",
      "308           0.0     1  \n",
      "419           0.0     1  \n",
      "453           0.0     1  \n",
      "...           ...   ...  \n",
      "55066         0.0     1  \n",
      "55067         0.0     1  \n",
      "55070         0.0     1  \n",
      "55196         0.0     1  \n",
      "55199         0.8     1  \n",
      "\n",
      "[677 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "fire_df = pd.read_csv('Fire_data.csv')\n",
    "\n",
    "######CLEAN DATA##########\n",
    "\n",
    "# only get rows in Butte, CA\n",
    "fire_df = fire_df[fire_df['state']=='CA']\n",
    "fire_df = fire_df[(fire_df['latitude']>=39.0) & (fire_df['latitude']<=41.0)]\n",
    "\n",
    "# Remove uneccesary rows\n",
    "fire_df = fire_df[['latitude', 'longitude', 'state', 'disc_clean_date', 'Temp_pre_15', 'Temp_pre_7', 'Wind_pre_15', 'Wind_pre_7','Hum_pre_15', 'Hum_pre_7','Prec_pre_15', 'Prec_pre_7']]\n",
    "fire_df = fire_df.drop(fire_df[fire_df['Prec_pre_15']==-1].index)\n",
    "fire_df = fire_df.drop(fire_df[fire_df['Prec_pre_7']==-1].index)\n",
    "\n",
    "# Target row (fire): 1=Fire, 0=no fire\n",
    "fire_df['fire']=1\n",
    "print(fire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd2556ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      latitude   longitude disc_clean_date  Temp_pre_15  Temp_pre_7  \\\n",
      "0    40.343056 -123.383056      2022-10-29         23.0         9.0   \n",
      "1    40.343056 -123.383056      2022-10-30         22.1         7.3   \n",
      "2    40.343056 -123.383056      2022-10-31         17.6         9.8   \n",
      "3    40.343056 -123.383056       2022-11-1         17.0         9.9   \n",
      "4    40.343056 -123.383056       2022-11-2         17.8         6.7   \n",
      "..         ...         ...             ...          ...         ...   \n",
      "339  40.343056 -123.383056       2023-10-3         17.9        10.8   \n",
      "340  40.343056 -123.383056       2023-10-4         19.1        10.6   \n",
      "341  40.343056 -123.383056       2023-10-5         14.2        12.2   \n",
      "342  40.343056 -123.383056       2023-10-6         11.9        11.2   \n",
      "343  40.343056 -123.383056       2023-10-7         12.9        10.9   \n",
      "\n",
      "     Wind_pre_15  Wind_pre_7  Hum_pre_15  Hum_pre_7  Prec_pre_15  Prec_pre_7  \\\n",
      "0            3.4        12.5        31.0       69.0          0.0        0.06   \n",
      "1            2.7         4.5        29.0       60.0          0.0        0.00   \n",
      "2            4.5         6.7        36.0       53.0          0.0        0.04   \n",
      "3            2.0         7.6        51.0       69.0          0.0        0.00   \n",
      "4            2.9         8.9        40.0       72.0          0.0        0.00   \n",
      "..           ...         ...         ...        ...          ...         ...   \n",
      "339          7.2         8.7        62.0       76.0          0.0        0.02   \n",
      "340          8.3         5.6        62.0       73.0          0.0        0.01   \n",
      "341         11.2         7.8        45.0       64.0          0.0        0.00   \n",
      "342          6.5         6.3        41.0       78.0          0.0        0.00   \n",
      "343          5.1         3.4        44.0       79.0          0.0        0.07   \n",
      "\n",
      "     Temp  Wind   Hum  Prec  fire  \n",
      "0    10.9   6.5  55.0  0.00     0  \n",
      "1    11.6   3.8  59.0  0.00     0  \n",
      "2    12.5   7.6  61.0  0.00     0  \n",
      "3     6.6  11.6  80.0  0.78     0  \n",
      "4     3.0   6.5  84.0  0.12     0  \n",
      "..    ...   ...   ...   ...   ...  \n",
      "339  14.4   3.4  60.0  0.00     0  \n",
      "340  17.1   4.3  44.0  0.00     0  \n",
      "341  18.7   4.5  32.0  0.00     0  \n",
      "342  19.5   4.3  34.0  0.00     0  \n",
      "343  19.8   6.5  41.0  0.00     0  \n",
      "\n",
      "[344 rows x 16 columns]\n",
      "latitude      -0.427649\n",
      "longitude      0.684510\n",
      "Temp_pre_15    0.305144\n",
      "Temp_pre_7     0.264536\n",
      "Wind_pre_15   -0.723722\n",
      "Wind_pre_7    -0.746663\n",
      "Hum_pre_15    -0.527762\n",
      "Hum_pre_7     -0.561280\n",
      "Prec_pre_15    0.064079\n",
      "Prec_pre_7     0.047451\n",
      "Temp                NaN\n",
      "Wind                NaN\n",
      "Hum                 NaN\n",
      "Prec                NaN\n",
      "fire           1.000000\n",
      "Name: fire, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "weather_df = pd.read_csv('Weather.csv')\n",
    "weather_df['fire']=0\n",
    "print(weather_df)\n",
    "df = pd.concat([weather_df, fire_df], axis=0)\n",
    "# print(df)\n",
    "df = df.sample(frac = 1)\n",
    "# print(df)\n",
    "mat=df.corr()\n",
    "print(mat['fire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdbdfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Conda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Temp_pre_7  Wind_pre_7  Hum_pre_7\n",
      "25       9.700000    2.900000  36.000000\n",
      "14535   35.000000    3.100000  12.000000\n",
      "34151   24.847826    1.251242  42.400621\n",
      "179      2.800000    9.400000  80.000000\n",
      "55196   27.876543    4.445679  31.074074\n",
      "...           ...         ...        ...\n",
      "327     23.000000    4.000000  33.000000\n",
      "59       3.000000    2.200000  89.000000\n",
      "38225  -14.547619    4.173214  81.648810\n",
      "3611     0.000000    0.000000   0.000000\n",
      "13332    0.000000    0.000000   0.000000\n",
      "\n",
      "[205 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['Temp_pre_7', 'Wind_pre_7', 'Hum_pre_7']]\n",
    "Y = df[['fire']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a01431a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Conda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6115\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.4179\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3689\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3566\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3480\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2880\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3235\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3468\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3468\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3468\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3468\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3468\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.3456\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3024\n",
      "Test Loss: 0.0000\n",
      "Test Accuracy: 0.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Conda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "C:\\Conda\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import tensorflow dependencies\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=150)\n",
    "\n",
    "#Test the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# save model and its architecture \n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2294e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print('No Kernnel')\n",
    "report = classification_report(y_test,y_pred)\n",
    "# f1scores.append(accuracy_score(y_test,y_pred, average = 'weighted'))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel = 'poly')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print('No Kernnel')\n",
    "report = classification_report(y_test,y_pred)\n",
    "# f1scores.append(accuracy_score(y_test,y_pred, average = 'weighted'))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38992179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With rbf Kernel\n",
    "svm_model = svm.SVC(kernel = 'rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print('rbf Kernel')\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eba966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Linear Kernel\n",
    "svm_model = svm.SVC(kernel = 'linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print('Linear Kernel')\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa769548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Sigmoid Kernel\n",
    "svm_model = svm.SVC(kernel = 'sigmoid')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print('Sigmoid Kernel')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75067155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## With intercept\n",
    "model = LogisticRegression(fit_intercept=True)\n",
    "\n",
    "# Fit the model to your training data.\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Compute the accuracy of your model on the testing set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print out the report\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa003eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)  # Weak learner for classification\n",
    "n_estimators = 50  # Number of estimators\n",
    "ada_classifier = AdaBoostClassifier(base_classifier, n_estimators=n_estimators)\n",
    "ada_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499cd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ada_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9efffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df2 = fire_df[['Temp_pre_7', 'Wind_pre_7','Hum_pre_7','Prec_pre_7', 'fire']]\n",
    "fire_df2.columns=['Temp', 'Wind', 'Hum', 'Prec', 'fire']\n",
    "weather_df2 = weather_df[['Temp', 'Wind', 'Hum', 'Prec', 'fire']]\n",
    "# print(fire_df2)\n",
    "# print(weather_df2)\n",
    "df2 = pd.concat([weather_df2, fire_df2], axis=0)\n",
    "df2 = df2.sample(frac = 1)\n",
    "mat=df2.corr()\n",
    "print(mat['fire'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print('No Kernnel')\n",
    "report = classification_report(y_test,y_pred)\n",
    "# f1scores.append(accuracy_score(y_test,y_pred, average = 'weighted'))\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb78472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
